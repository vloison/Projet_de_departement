{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.misc import triplet_to_str\n",
    "from preprocessing.database import clean_database, download_database\n",
    "from preprocessing.sets import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', help='Path to the config file', default='./default_config.yml')\n",
    "parser.add_argument('--log-dir', help='Path to the log directory', default='../log/')\n",
    "parser.add_argument('--posters', help='Path to the posters', default='../data/posters/')\n",
    "parser.add_argument('--models-dir', help='Path to the saved models', default='../data/models/')\n",
    "parser.add_argument('--sets-dir', help='Path to the training and testing sets', default='../data/sets/')\n",
    "parser.add_argument('--database', help='Path to the databse csv', default='../data/poster_data.csv')\n",
    "parser.add_argument('--csv', help='Path to the clean csv', default='../data/')\n",
    "parser.add_argument('-s', '--save', help='Save model', action='store_true')\n",
    "parser.add_argument('-v', '--verbose', help='Verbose', action='store_true')\n",
    "\n",
    "str_args = '-v -s'.split()\n",
    "args, _ = parser.parse_known_args(str_args)\n",
    "\n",
    "logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(args.config, encoding='utf-8'))\n",
    "\n",
    "nb_genres = len(config[\"genres\"])\n",
    "input_size = config[\"image_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendix_split = 's{}t{}_'.format(\n",
    "    config['size_per_genre'],\n",
    "    config['testing_split']\n",
    ") + triplet_to_str(config['image_size']) + '_' + str(nb_genres) + \".npy\"\n",
    "\n",
    "data_name = [Path(prefix+appendix_split) for prefix in\n",
    "    [args.sets_dir + 'xtr_',\n",
    "    args.sets_dir + 'ytr_',\n",
    "    args.sets_dir + 'idtr_',\n",
    "    args.sets_dir + 'xtest_',\n",
    "    args.sets_dir + 'ytest_',\n",
    "    args.sets_dir + 'idtest_']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/sets/xtr_s700t0.15_100-100-3_7.npy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already cleaned\n"
     ]
    }
   ],
   "source": [
    "selection_name = args.csv+'clean_poster_data_'+str(nb_genres)+'.csv'\n",
    "\n",
    "if Path(selection_name).exists():\n",
    "    if args.verbose:\n",
    "        print('Database already cleaned')\n",
    "    clean_movies = pd.read_csv(Path(selection_name))\n",
    "else:\n",
    "    clean_movies = clean_database(Path(args.database))\n",
    "    if args.save:\n",
    "        clean_movies.to_csv(Path(selection_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing sets alreadey made\n"
     ]
    }
   ],
   "source": [
    "if data_name[0].exists() and data_name[1].exists() and data_name[2].exists() and data_name[3].exists() and data_name[4].exists() and data_name[5].exists():\n",
    "    if args.verbose:\n",
    "        print('Training and testing sets alreadey made')\n",
    "    train_posters, train_genres, train_ids = np.load(data_name[0]), np.load(data_name[1]), np.load(data_name[2])\n",
    "    test_posters, test_genres, test_ids = np.load(data_name[3]), np.load(data_name[4]), np.load(data_name[5])\n",
    "\n",
    "else:\n",
    "    train_posters, train_genres, train_ids, test_posters, test_genres, test_ids = preprocess_data(\n",
    "        clean_movies, config['genres'], config['size_per_genre'], args.posters, config['image_size'],\n",
    "        config['seed'], testing_split=config['testing_split'], verbose=args.verbose, logger=logger\n",
    "    )\n",
    "    if args.save:\n",
    "        sets_path = Path(args.sets_dir)\n",
    "        if not sets_path.exists():\n",
    "            sets_path.mkdir()\n",
    "        np.save(data_name[0], train_posters)\n",
    "        np.save(data_name[1], train_genres)\n",
    "        np.save(data_name[2], train_ids)\n",
    "        np.save(data_name[3], test_posters)\n",
    "        np.save(data_name[4], test_genres)\n",
    "        np.save(data_name[5], test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = keras.applications.resnet_v2.ResNet50V2(\n",
    "    input_shape=input_size, include_top=False, weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = resnet.predict(train_posters.astype(np.float32)).reshape(\n",
    "    (len(train_posters), -1)\n",
    ")\n",
    "    \n",
    "test_features = resnet.predict(test_posters.astype(np.float32)).reshape(\n",
    "    (len(test_posters), -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(train_features, train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_genres = knn.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action (0.14285714285714285):\n",
      "    Action: 0.8857142857142857\n",
      "    Animation: 0.047619047619047616\n",
      "    Comédie: 0.01904761904761905\n",
      "    Comédie dramatique: 0.009523809523809525\n",
      "    Documentaire: 0.0\n",
      "    Drame: 0.01904761904761905\n",
      "    Thriller-Policier: 0.01904761904761905\n",
      "\n",
      "Animation (0.14285714285714285):\n",
      "    Action: 0.7047619047619048\n",
      "    Animation: 0.21904761904761905\n",
      "    Comédie: 0.02857142857142857\n",
      "    Comédie dramatique: 0.0\n",
      "    Documentaire: 0.0380952380952381\n",
      "    Drame: 0.0\n",
      "    Thriller-Policier: 0.009523809523809525\n",
      "\n",
      "Comédie (0.14285714285714285):\n",
      "    Action: 0.819047619047619\n",
      "    Animation: 0.0380952380952381\n",
      "    Comédie: 0.10476190476190476\n",
      "    Comédie dramatique: 0.0\n",
      "    Documentaire: 0.01904761904761905\n",
      "    Drame: 0.01904761904761905\n",
      "    Thriller-Policier: 0.0\n",
      "\n",
      "Comédie dramatique (0.14285714285714285):\n",
      "    Action: 0.8666666666666667\n",
      "    Animation: 0.02857142857142857\n",
      "    Comédie: 0.0380952380952381\n",
      "    Comédie dramatique: 0.009523809523809525\n",
      "    Documentaire: 0.047619047619047616\n",
      "    Drame: 0.009523809523809525\n",
      "    Thriller-Policier: 0.0\n",
      "\n",
      "Documentaire (0.14285714285714285):\n",
      "    Action: 0.8095238095238095\n",
      "    Animation: 0.01904761904761905\n",
      "    Comédie: 0.01904761904761905\n",
      "    Comédie dramatique: 0.01904761904761905\n",
      "    Documentaire: 0.11428571428571428\n",
      "    Drame: 0.01904761904761905\n",
      "    Thriller-Policier: 0.0\n",
      "\n",
      "Drame (0.14285714285714285):\n",
      "    Action: 0.8571428571428571\n",
      "    Animation: 0.01904761904761905\n",
      "    Comédie: 0.01904761904761905\n",
      "    Comédie dramatique: 0.0\n",
      "    Documentaire: 0.02857142857142857\n",
      "    Drame: 0.02857142857142857\n",
      "    Thriller-Policier: 0.047619047619047616\n",
      "\n",
      "Thriller-Policier (0.14285714285714285):\n",
      "    Action: 0.8285714285714286\n",
      "    Animation: 0.01904761904761905\n",
      "    Comédie: 0.02857142857142857\n",
      "    Comédie dramatique: 0.009523809523809525\n",
      "    Documentaire: 0.05714285714285714\n",
      "    Drame: 0.009523809523809525\n",
      "    Thriller-Policier: 0.047619047619047616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres_inv = {config['genres'][k]: k for k in config['genres'].keys()}\n",
    "\n",
    "predictions = np.array([genres_inv[k] for k in np.argmax(predicted_genres, axis=1)])\n",
    "ground_truth = np.array([genres_inv[k] for k in np.argmax(test_genres, axis=1)])\n",
    "\n",
    "genres = config[\"genres\"]\n",
    "\n",
    "results_per_genre = {\n",
    "    genre_true : {genre_pred : 0 for genre_pred in genres}\n",
    "    for genre_true in genres\n",
    "}\n",
    "\n",
    "total_per_genre = {\n",
    "    genre : 0\n",
    "    for genre in genres\n",
    "}\n",
    "\n",
    "n = len(predictions)\n",
    "for i in range(n):\n",
    "    results_per_genre[ground_truth[i]][predictions[i]] += 1\n",
    "    total_per_genre[ground_truth[i]] += 1\n",
    "\n",
    "for genre_true in genres:\n",
    "    print(\n",
    "        genre_true + \" (\" + str(total_per_genre[genre_true] / n) + \"):\"\n",
    "    )\n",
    "    for genre_pred in genres:\n",
    "        print(\n",
    "            \"    \" + genre_pred + \": \" + str(\n",
    "                results_per_genre[genre_true][genre_pred] / total_per_genre[genre_true]\n",
    "            )\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20136054421768707\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "for genre in genres:\n",
    "    accuracy += results_per_genre[genre][genre]\n",
    "\n",
    "accuracy /= len(test_posters)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
