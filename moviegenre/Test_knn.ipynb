{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from get_data import main\n",
    "from cnn.training import get_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', help='Path to the config file', default='./default_config.yml')\n",
    "parser.add_argument('--log-dir', help='Path to the log directory', default='../log/')\n",
    "parser.add_argument('--posters', help='Path to the posters', default='../data/posters/')\n",
    "parser.add_argument('--models-dir', help='Path to the saved models', default='../data/models/')\n",
    "parser.add_argument('--sets-dir', help='Path to the training and testing sets', default='../data/sets/')\n",
    "parser.add_argument('--database', help='Path to the databse csv', default='../data/poster_data.csv')\n",
    "parser.add_argument('--csv', help='Path to the clean csv', default='../data/')\n",
    "parser.add_argument('-s', '--save', help='Save model', action='store_true')\n",
    "parser.add_argument('-v', '--verbose', help='Verbose', action='store_true')\n",
    "\n",
    "str_args = '-v -s'.split()\n",
    "args, _ = parser.parse_known_args(str_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 561/11935 [00:00<00:02, 5607.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already cleaned\n",
      "Posters database downloading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 10544/11935 [00:01<00:00, 6280.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error HTTP Error 404: Not Found with film 9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11935/11935 [00:01<00:00, 7249.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database downloaded\n",
      "Training and testing sets already made\n"
     ]
    }
   ],
   "source": [
    "clean_movies, train_posters, train_genres, train_ids, test_posters, test_genres, test_ids, model_name, save_model, verbose = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already trained\n",
      "No training history\n"
     ]
    }
   ],
   "source": [
    "model, training_history = get_trained_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 532s 6us/step\n"
     ]
    }
   ],
   "source": [
    "resnet = keras.applications.resnet_v2.ResNet50V2(\n",
    "    input_shape=input_size, include_top=False, weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_resnet = resnet.predict(train_posters.astype(np.float32)).reshape(\n",
    "    (len(train_posters), -1)\n",
    ")\n",
    "    \n",
    "test_features_resnet = resnet.predict(test_posters.astype(np.float32)).reshape(\n",
    "    (len(test_posters), -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrammes de couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-58b51239b15f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-58b51239b15f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    train_features_rgb_r =\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Training sets\n",
    "train_features_rgb_r = \n",
    "train_features_rgb_g= np.load('../data/features/histo_rgb_g_train.npy')\n",
    "train_features_rgb_b = np.load('../data/features/histo_rgb_b_train.npy')\n",
    "print('shape train rgb r', train_features_rgb_r.shape)\n",
    "print('shape train rgb g', train_features_rgb_g.shape)\n",
    "print('shape train rgb b', train_features_rgb_b.shape)\n",
    "\n",
    "train_features_rgb = np.concatenate((train_features_rgb_r, train_features_rgb_g, train_features_rgb_b), axis=1)\n",
    "print('Shape train rgb', train_features_rgb.shape)\n",
    "\n",
    "#Testing sets\n",
    "test_features_rgb_r = np.load('../data/features/histo_rgb_r_test.npy')\n",
    "test_features_rgb_g = np.load('../data/features/histo_rgb_g_test.npy')\n",
    "test_features_rgb_b = np.load('../data/features/histo_rgb_b_test.npy')\n",
    "print('shape test rgb r', test_features_rgb_r.shape)\n",
    "print('shape test rgb g', test_features_rgb_g.shape)\n",
    "print('shape test rgb b', test_features_rgb_b.shape)\n",
    "\n",
    "test_features_rgb = np.concatenate((test_features_rgb_r, test_features_rgb_g, test_features_rgb_b), axis=1)\n",
    "print('Shape test rgb', test_features_rgb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sets\n",
    "train_features_lab_l = np.load('../data/features/histo_lab_l_train.npy')\n",
    "train_features_lab_a= np.load('../data/features/histo_lab_a_train.npy')\n",
    "train_features_lab_b = np.load('../data/features/histo_lab_b_train.npy')\n",
    "print('shape train lab l', train_features_lab_l.shape)\n",
    "print('shape train lab a', train_features_lab_a.shape)\n",
    "print('shape train lab b', train_features_lab_b.shape)\n",
    "\n",
    "train_features_lab = np.concatenate((train_features_lab_l, train_features_lab_a, train_features_lab_b), axis=1)\n",
    "\n",
    "# Testing sets\n",
    "test_features_lab_l = np.load('../data/features/histo_lab_l_test.npy')\n",
    "test_features_lab_a = np.load('../data/features/histo_lab_a_test.npy')\n",
    "test_features_lab_b = np.load('../data/features/histo_lab_b_test.npy')\n",
    "print('shape test lab l', test_features_lab_l.shape)\n",
    "print('shape test lab a', test_features_lab_a.shape)\n",
    "print('shape test lab b', test_features_lab_b.shape)\n",
    "\n",
    "test_features_lab = np.concatenate((test_features_lab_l, test_features_lab_a, test_features_lab_b), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des plus proches voisins sur un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des prédictions sur le testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "predicted_genres = KNN(clean_movies, train_posters, train_features_lab, train_genres, train_ids, test_posters, test_features_lab, test_ids, -1, k, print_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_inv = {config['genres'][k]: k for k in config['genres'].keys()}\n",
    "print('genres', list(config['genres']))\n",
    "\n",
    "def visualisation_resultats(predicted_genres, test_genres, kneighbors, save=False):\n",
    "    predictions = np.array([genres_inv[k] for k in np.argmax(predicted_genres, axis=1)])\n",
    "    ground_truth = np.array([genres_inv[k] for k in np.argmax(test_genres, axis=1)])\n",
    "\n",
    "    genres = config[\"genres\"]\n",
    "    # results_per_genre : matrice donc les lignes sont les vrais genres, et les colonnes sont les genres prédits\n",
    "    results_per_genre = {\n",
    "        genre_true : {genre_pred : 0 for genre_pred in genres}\n",
    "        for genre_true in genres\n",
    "    }\n",
    "    #print(\"results per genre\", results_per_genre)\n",
    "    #print('results per genre ligne', results_per_genre['Action'].values())\n",
    "    # total_per_genre : vecteur qui comptabilise le nombre de représentants de chaque genre\n",
    "    total_per_genre = {\n",
    "        genre : 0\n",
    "        for genre in genres\n",
    "    }\n",
    "    # Mise à jour de results_per_genre et total_per_genre en fonction des prédictions\n",
    "    n = len(predictions)\n",
    "    for i in range(n):\n",
    "        results_per_genre[ground_truth[i]][predictions[i]] += 1\n",
    "        total_per_genre[ground_truth[i]] += 1\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = 0\n",
    "    for genre in genres:\n",
    "        accuracy += results_per_genre[genre][genre]\n",
    "    accuracy /= len(test_posters)\n",
    "    print('accuracy:', accuracy)\n",
    "\n",
    "    # Visualisation:\n",
    "    genres_list = list(config['genres'])\n",
    "    for iterateur in genres_list:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.title('Prédictions sur les films de genre ' + iterateur + ' k='+str(k) +\", Accuracy totale:\" + str(accuracy))\n",
    "        plt.bar(genres_list, results_per_genre[iterateur].values())\n",
    "        plt.show()\n",
    "        if save:\n",
    "            plt.savefig('../results/Resnet+kNN/'+iterateur+'_k='+str(kneighbors)+'.png')\n",
    "    return(accuracy)\n",
    "\n",
    "visualisation_resultats(predicted_genres, test_genres, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction des genres:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation des features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les blocs suivant sert à \"automatiser\" la sélection des features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POUR LA METHODE RESNET :\n",
    "\n",
    "RESNET = False #encore à faire\n",
    "\n",
    "# POUR LES HISTOGRAMMES :\n",
    "\n",
    "# On renseigne d'abord si on veut l'histogramme pour la couleur considérée, puis le nombre de bins\n",
    "# Attention, les histogrammes avec le nombre de bins correspondants doivent avoir été calculés\n",
    "\n",
    "RGB_R = False\n",
    "RGB_R_bins = 256\n",
    "\n",
    "RGB_G = False\n",
    "RGB_G_bins = 256 \n",
    "\n",
    "RGB_B = False\n",
    "RGB_B_bins = 256 \n",
    "\n",
    "LAB_L = True\n",
    "LAB_L_bins = 16\n",
    "\n",
    "LAB_A = True\n",
    "LAB_A_bins = 16\n",
    "\n",
    "LAB_B = True\n",
    "LAB_B_bins = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le bloc suivant, on définit le dictionnaire en fonction de nos choix de features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train = Observations(1) # 4 pour la distance\n",
    "obs_test = Observations(1)\n",
    "\n",
    "if RGB_R:\n",
    "    obs_train.add_histo_feature(np.load('../data/features/histo_rgb_r_train_' + str(RGB_R_bins) + '.npy'))\n",
    "    obs_test.add_histo_feature(np.load('../data/features/histo_rgb_r_test_' + str(RGB_R_bins) + '.npy'))\n",
    "\n",
    "if RGB_G:\n",
    "    obs_train.add_histo_feature(np.load('../data/features/histo_rgb_g_train_' + str(RGB_G_bins) + '.npy'))\n",
    "    obs_test.add_histo_feature(np.load('../data/features/histo_rgb_g_test_' + str(RGB_G_bins) + '.npy'))\n",
    "\n",
    "if RGB_B:\n",
    "    obs_train.add_histo_feature(np.load('../data/features/histo_rgb_b_train_' + str(RGB_B_bins) + '.npy'))\n",
    "    obs_test.add_histo_feature(np.load('../data/features/histo_rgb_b_test_' + str(RGB_B_bins) + '.npy'))\n",
    "    \n",
    "if LAB_L:\n",
    "    obs_train.add_histo_feature(np.load('../data/features/histo_lab_l_train_' + str(LAB_L_bins) + '.npy'))\n",
    "    obs_test.add_histo_feature(np.load('../data/features/histo_lab_l_test_' + str(LAB_L_bins) + '.npy'))\n",
    "    \n",
    "if LAB_A:\n",
    "    obs_train.add_histo_feature(np.load('../data/features/histo_lab_a_train_' + str(LAB_A_bins) + '.npy'))\n",
    "    obs_test.add_histo_feature(np.load('../data/features/histo_lab_a_test_' + str(LAB_A_bins) + '.npy'))\n",
    "    \n",
    "if LAB_B:\n",
    "    obs_train.add_histo_feature(np.load('../data/features/histo_lab_b_train_' + str(LAB_B_bins) + '.npy'))\n",
    "    obs_test.add_histo_feature(np.load('../data/features/histo_lab_b_test_' + str(LAB_B_bins) + '.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=7\n",
    "obs_train.compute_distance()\n",
    "\n",
    "predicted_genres = KNN(\n",
    "    dataset=clean_movies,\n",
    "    Xtr=train_posters,\n",
    "    tr_features=obs_train.observations,\n",
    "    Ytr=train_genres,\n",
    "    training_ids=train_ids,\n",
    "    Xtest=test_posters,\n",
    "    test_features=obs_test.observations,\n",
    "    testing_ids=test_ids,\n",
    "    ind=-1,\n",
    "    k=k,\n",
    "    metric=obs_train.distance,\n",
    "    print_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_inv = {config['genres'][k]: k for k in config['genres'].keys()}\n",
    "print('genres', list(config['genres']))\n",
    "\n",
    "def visualisation_resultats(predicted_genres, test_genres, kneighbors, save=False):\n",
    "    predictions = np.array([genres_inv[k] for k in np.argmax(predicted_genres, axis=1)])\n",
    "    ground_truth = np.array([genres_inv[k] for k in np.argmax(test_genres, axis=1)])\n",
    "\n",
    "    genres = config[\"genres\"]\n",
    "    # results_per_genre : matrice donc les lignes sont les vrais genres, et les colonnes sont les genres prédits\n",
    "    results_per_genre = {\n",
    "        genre_true : {genre_pred : 0 for genre_pred in genres}\n",
    "        for genre_true in genres\n",
    "    }\n",
    "    #print(\"results per genre\", results_per_genre)\n",
    "    #print('results per genre ligne', results_per_genre['Action'].values())\n",
    "    # total_per_genre : vecteur qui comptabilise le nombre de représentants de chaque genre\n",
    "    total_per_genre = {\n",
    "        genre : 0\n",
    "        for genre in genres\n",
    "    }\n",
    "    # Mise à jour de results_per_genre et total_per_genre en fonction des prédictions\n",
    "    n = len(predictions)\n",
    "    for i in range(n):\n",
    "        results_per_genre[ground_truth[i]][predictions[i]] += 1\n",
    "        total_per_genre[ground_truth[i]] += 1\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = 0\n",
    "    for genre in genres:\n",
    "        accuracy += results_per_genre[genre][genre]\n",
    "    accuracy /= len(test_posters)\n",
    "    print('accuracy:', accuracy)\n",
    "\n",
    "    # Visualisation:\n",
    "    genres_list = list(config['genres'])\n",
    "    for iterateur in genres_list:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.title('Prédictions sur les films de genre ' + iterateur + ' k='+str(k) +\", Accuracy totale:\" + str(accuracy))\n",
    "        plt.bar(genres_list, results_per_genre[iterateur].values())\n",
    "        plt.show()\n",
    "        if save:\n",
    "            plt.savefig('../results/Resnet+kNN/'+iterateur+'_k='+str(kneighbors)+'.png')\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation_resultats(predicted_genres, test_genres, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
